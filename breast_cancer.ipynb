{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321bf637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "(455, 30) (455, 2)\n",
      "(114, 30) (114, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch No: 0 Train Accuracy: 0.4087912\n",
      "Test Accuracy: 0.22807017\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "\n",
    "n_nodes_h1 = 100\n",
    "n_nodes_h2 = 100\n",
    "n_nodes_h3 = 100\n",
    "n_nodes_h4 = 100\n",
    "n_classes = 2\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "f = open(r'E:\\Project 2022\\Cancer-detection-using-CNN-master\\Data_Set.txt')\n",
    "i=0\n",
    "for line in f.readlines():\n",
    "    line = line.split(',')\n",
    "    i+=1  \n",
    "    if(i<456):\n",
    "        if(line[1] == 'M'):\n",
    "            train_labels.append([float(1),float(0)])\n",
    "        elif(line[1] == 'B'):\n",
    "             train_labels.append([float(0),float(1)])\n",
    "        del line[1]\n",
    "        del line[0]\n",
    "        train_data.append([np.float32(j) for j in line])\n",
    "        \n",
    "    else:\n",
    "        if(line[1] == 'M'):\n",
    "            test_labels.append([float(1),float(0)])\n",
    "        elif(line[1] == 'B'):\n",
    "             test_labels.append([float(0),float(1)])\n",
    "        del line[1]\n",
    "        del line[0]\n",
    "        test_data.append([np.float32(j) for j in line])\n",
    "                \n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "\n",
    "print(train_data.shape,train_labels.shape)\n",
    "print(test_data.shape,test_labels.shape)\n",
    "\n",
    "x = tf.placeholder(shape=[None, 30], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "\n",
    "hidden_layer_1 = {'weights':tf.Variable(tf.random_normal([30,n_nodes_h1], stddev=0.01, dtype=tf.float32)),'biases':tf.Variable(tf.random_normal([n_nodes_h1], stddev=0.01, dtype=tf.float32))}\n",
    "hidden_layer_2 = {'weights':tf.Variable(tf.random_normal([n_nodes_h1,n_nodes_h2], stddev=0.01, dtype=tf.float32)),'biases':tf.Variable(tf.random_normal([n_nodes_h2], stddev=0.01, dtype=tf.float32))}\n",
    "#hidden_layer_3 = {'weights':tf.Variable(tf.random_normal([n_nodes_h2,n_nodes_h3], stddev=0.01, dtype=tf.float32)),'biases':tf.Variable(tf.random_normal([n_nodes_h3], stddev=0.01, dtype=tf.float32))}\n",
    "#hidden_layer_4 = {'weights':tf.Variable(tf.random_normal([n_nodes_h3,n_nodes_h4], stddev=0.01, dtype=tf.float32)),'biases':tf.Variable(tf.random_normal([n_nodes_h3], stddev=0.01, dtype=tf.float32))}\n",
    "output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_h2,n_classes], stddev=0.01, dtype=tf.float32)),'biases':tf.Variable(tf.random_normal([n_classes], stddev=0.01, dtype=tf.float32))}\n",
    "\n",
    "layer1 = tf.add(tf.matmul(x ,hidden_layer_1['weights']),hidden_layer_1['biases'])\n",
    "layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "layer2 = tf.add(tf.matmul(layer1,hidden_layer_2['weights']),hidden_layer_2['biases'])\n",
    "layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "#layer3 = tf.add(tf.matmul(layer2,hidden_layer_3['weights']),hidden_layer_3['biases'])\n",
    "#layer3 = tf.nn.tanh(layer3)\n",
    "\n",
    "#layer4 = tf.add(tf.matmul(layer3,hidden_layer_4['weights']),hidden_layer_4['biases'])\n",
    "#layer4 = tf.nn.tanh(layer4)\n",
    "\n",
    "output = tf.add(tf.matmul(layer2,output_layer['weights']), output_layer['biases'])\n",
    "    \n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = output,labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "number_epochs = 5\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(number_epochs+1):\n",
    "        sess.run(train,feed_dict={x:train_data, y:train_labels})\n",
    "            \n",
    "        if i%10000 == 0:\n",
    "            #print('Epoch = ',str(i+1), 'Loss = ',str(epoch_loss))\n",
    "            correct = tf.equal(tf.argmax(output,1),tf.argmax(y,1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct,'float32'))\n",
    "            print('Epoch No:',str(i),'Train Accuracy:',accuracy.eval({x:train_data,y:train_labels}))\n",
    "            #print(sess.run(tf.nn.softmax(output), feed_dict= {x:a}))\n",
    "            #print(sess.run(hidden_layer_1['weights']))\n",
    "\n",
    "    correct = tf.equal(tf.argmax(output,1),tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,'float32'))\n",
    "\n",
    "    #print(test_data.shape,test_labels.shape)   \n",
    "    print('Test Accuracy:',accuracy.eval({x:test_data,y:test_labels}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b29dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e2575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
